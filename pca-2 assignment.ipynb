{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612459b9-d766-4582-a0f2-b33518b4417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f0d1a-f6c2-4379-8294-5ca9d9043939",
   "metadata": {},
   "outputs": [],
   "source": [
    "In the context of PCA, a projection refers to the process of transforming data from a higher-dimensional space to a lower-dimensional subspace while preserving as much variance as possible. PCA aims to find a set of orthogonal axes (principal components) along which the data has the highest variance. The first principal component captures the most variance, the second captures the second most, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c6a08-966b-4d05-9ec0-97efa218a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bfb67-4a3d-4dc0-8b08-64f428ace8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA involves an optimization problem where the goal is to find the axes (principal components) that maximize the variance of the projected data. Mathematically, this can be formulated as an eigenvalue problem, where the principal components are the eigenvectors of the covariance matrix of the data.\n",
    "\n",
    "The optimization problem in PCA can be summarized as follows:\n",
    "\n",
    "Compute the covariance matrix of the data.\n",
    "Find the eigenvalues and eigenvectors of the covariance matrix.\n",
    "Sort the eigenvalues in descending order and select the corresponding eigenvectors as the principal components.\n",
    "The eigenvalues represent the amount of variance explained by each principal component. By choosing a subset of the top eigenvalues (and their corresponding eigenvectors), you can achieve dimensionality reduction while retaining most of the original data's variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ecdb3c-7d5b-4c8a-a3ca-76e409d24de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c4f83-1e20-442e-9f79-f37730c16237",
   "metadata": {},
   "outputs": [],
   "source": [
    "Covariance matrices play a central role in PCA. The covariance matrix summarizes the relationships between different dimensions (variables) in the data. Diagonal elements of the covariance matrix represent the variances of individual variables, while off-diagonal elements represent the covariances between pairs of variables.\n",
    "\n",
    "In PCA, the covariance matrix is used to compute the eigenvalues and eigenvectors, which are essential for determining the principal components. The eigenvectors of the covariance matrix represent the directions along which the data varies the most, and the eigenvalues indicate the amount of variance along each eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f5edb-ca49-4108-82aa-f6a2f250977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638835f6-8582-461c-ad46-9778085bdda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "The choice of the number of principal components affects the trade-off between dimensionality reduction and preserving information. Generally, you want to retain as much variance as possible while reducing dimensionality. However, using too few principal components can result in information loss, while using too many can lead to overfitting.\n",
    "\n",
    "A common approach to determine the number of principal components is to look at the explained variance ratio. This ratio tells you the proportion of the total variance in the data that is explained by each principal component. You can plot the cumulative explained variance and choose a number of components that retain a sufficiently high amount of variance, typically capturing 95% or more of the total variance.\n",
    "\n",
    "In summary, selecting the right number of principal components involves a balance between dimensionality reduction and retaining meaningful information from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213da87a-4c48-48c0-ab5b-129643ae4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b267e-4e9f-4eb1-b03d-6677776934d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA can be used for feature selection by identifying the principal components that capture the most significant variance in the data. Instead of selecting individual features, you can select a subset of principal components as new features. This can help in reducing the dimensionality of the dataset while retaining most of the relevant information. Benefits of using PCA for feature selection include:\n",
    "\n",
    "Dimensionality Reduction: PCA can reduce the number of features while maintaining the most important information, thus simplifying the model and reducing overfitting.\n",
    "\n",
    "Noise Reduction: By focusing on the principal components with high variance, you may remove noise and retain the underlying patterns in the data.\n",
    "\n",
    "Collinearity Handling: PCA can mitigate multicollinearity issues where features are highly correlated, as it transforms the features into uncorrelated principal components.\n",
    "\n",
    "Visualization: Projecting high-dimensional data onto a lower-dimensional space allows for easier visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc125a-382d-4346-957e-0fd4fc5590f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057ea50-11e0-43bf-ba51-8096fa7a98d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d937f3-33f0-4998-aab3-4f42b084822a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0abe14-09e5-4a54-baa0-b0cf49881b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823deba-30fb-4506-ae60-25a7b59fad99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9d6bd-f50e-4a52-80f1-a1f127518e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a11bda-c18f-4463-8538-e8ffe5328d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295bf245-b4d2-4169-be51-d8bb466b81ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b48f8-2811-4f3a-820e-99aa34cba8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6d41e-67a2-45fc-a6a0-4b2053298155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15811ccd-8798-497c-87e2-3850824b9c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf4e51-a29e-4df7-bdfa-22d7f26670c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
